{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd39abd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A parameter is an internal variable of a model that is learned from training data. For example, in linear regression, the slope and intercept are parameters.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. What is a parameter?\n",
    "\n",
    "\n",
    "'''A parameter is an internal variable of a model that is learned from training data. For example, in linear regression, the slope and intercept are parameters.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde6b096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Correlation measures the statistical relationship between two variables. It ranges from -1 to +1:\\n\\n+1 = perfect positive correlation\\n\\n0 = no correlation\\n\\n-1 = perfect negative correlation\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. What is correlation?What does negative correlation mean?\n",
    "\n",
    "\n",
    "\n",
    "'''Correlation measures the statistical relationship between two variables. It ranges from -1 to +1:\n",
    "\n",
    "+1 = perfect positive correlation\n",
    "\n",
    "0 = no correlation\n",
    "\n",
    "-1 = perfect negative correlation\n",
    "'''\n",
    "'''\n",
    "A negative correlation means that as one variable increases, the other decreases.\n",
    "For example, hours spent watching TV and exam scores might be negatively correlated.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db881396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Machine Learning (ML) is a subset of AI that enables systems to learn from data and make predictions or decisions.\\n\\nMain components:\\n\\nData: Input to train the model.\\n\\nModel/Algorithm: Learns from data.\\n\\nLoss Function: Measures prediction error.\\n\\nOptimizer: Reduces loss.\\n\\nEvaluation Metrics: Judge model performance. '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Define Machine Learning. What are the main components in Machine Learning?\n",
    "\n",
    "\n",
    "\n",
    "''' Machine Learning (ML) is a subset of AI that enables systems to learn from data and make predictions or decisions.\n",
    "\n",
    "Main components:\n",
    "\n",
    "Data: Input to train the model.\n",
    "\n",
    "Model/Algorithm: Learns from data.\n",
    "\n",
    "Loss Function: Measures prediction error.\n",
    "\n",
    "Optimizer: Reduces loss.\n",
    "\n",
    "Evaluation Metrics: Judge model performance. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f29b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A low loss value indicates that the model is making predictions close to the actual values. A high loss means poor predictions.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. How does loss value help in determining whether the model is good or not?\n",
    "\n",
    "\n",
    "\n",
    "'''A low loss value indicates that the model is making predictions close to the actual values. A high loss means poor predictions.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5976f584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Continuous: Numeric values on a scale (e.g., height, salary).\\n\\nCategorical: Discrete labels (e.g., gender, color, type of product).'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. What are continuous and categorical variables?\n",
    "\n",
    "\n",
    "'''Continuous: Numeric values on a scale (e.g., height, salary).\n",
    "\n",
    "Categorical: Discrete labels (e.g., gender, color, type of product).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcf35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Label Encoding: Converts categories to numbers.\\n\\nOne-Hot Encoding: Creates binary columns.\\n\\nOrdinal Encoding: For ordered categories.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. How do we handle categorical variables in Machine Learning? Common techniques:\n",
    "\n",
    "\n",
    "'''Label Encoding: Converts categories to numbers.\n",
    "\n",
    "One-Hot Encoding: Creates binary columns.\n",
    "\n",
    "Ordinal Encoding: For ordered categories.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59c95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training set: Used to train the model.\\n\\nTesting set: Used to evaluate model performance on unseen data.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7. What do you mean by training and testing a dataset?\n",
    "\n",
    "\n",
    "'''Training set: Used to train the model.\n",
    "\n",
    "Testing set: Used to evaluate model performance on unseen data.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d172a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A module in scikit-learn that provides preprocessing functions like:\\n\\nEncoding\\n\\nScaling\\n\\nNormalization\\n\\nImputation\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8. What is sklearn.preprocessing?\n",
    "'''A module in scikit-learn that provides preprocessing functions like:\n",
    "\n",
    "Encoding\n",
    "\n",
    "Scaling\n",
    "\n",
    "Normalization\n",
    "\n",
    "Imputation\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1edd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A test set is a portion of data not seen by the model during training, used to evaluate its predictive performance.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9. What is a Test set?\n",
    "'''A test set is a portion of data not seen by the model during training, used to evaluate its predictive performance.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611d820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10. How do we split data for model fitting in Python? How do you approach a Machine Learning problem?\n",
    "'''from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)'''\n",
    "\n",
    "\n",
    "'''\n",
    "Understand the problem\n",
    "\n",
    "Collect and clean data\n",
    "\n",
    "Perform EDA (Exploratory Data Analysis)\n",
    "\n",
    "Feature engineering\n",
    "\n",
    "Choose model\n",
    "\n",
    "Train model\n",
    "\n",
    "Evaluate model\n",
    "\n",
    "Tune hyperparameters\n",
    "\n",
    "Test and deploy\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc6754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EDA helps:\\n\\nUnderstand data structure\\n\\nDetect missing or outlier values\\n\\nFind patterns and correlations\\n\\nGuide feature engineering\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11. Why do we perform EDA before fitting a model to the data?\n",
    "'''EDA helps:\n",
    "\n",
    "Understand data structure\n",
    "\n",
    "Detect missing or outlier values\n",
    "\n",
    "Find patterns and correlations\n",
    "\n",
    "Guide feature engineering\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a3be82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Correlation measures the statistical relationship between two variables. It ranges from -1 to +1:\\n\\n+1 = perfect positive correlation\\n\\n0 = no correlation\\n\\n-1 = perfect negative correlation\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12. What is correlation?\n",
    "'''Correlation measures the statistical relationship between two variables. It ranges from -1 to +1:\n",
    "\n",
    "+1 = perfect positive correlation\n",
    "\n",
    "0 = no correlation\n",
    "\n",
    "-1 = perfect negative correlation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef041bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA negative correlation means that as one variable increases, the other decreases.\\nFor example, hours spent watching TV and exam scores might be negatively correlated.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#13. What does negative correlation mean?\n",
    "'''\n",
    "A negative correlation means that as one variable increases, the other decreases.\n",
    "For example, hours spent watching TV and exam scores might be negatively correlated.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b739f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandas as pd\\ndf.corr()  \\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14. How can you find correlation between variables in Python?\n",
    "'''import pandas as pd\n",
    "df.corr()  \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2dda174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCausation means one variable directly affects another.\\n\\nDifference:\\n\\nCorrelation: A and B change together.\\n\\nCausation: A causes B.\\n\\nExample: Ice cream sales and drowning deaths correlate, but hot weather (a third factor) causes both.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#15. What is causation? Difference between correlation and causation:\n",
    "\n",
    "'''\n",
    "Causation means one variable directly affects another.\n",
    "\n",
    "Difference:\n",
    "\n",
    "Correlation: A and B change together.\n",
    "\n",
    "Causation: A causes B.\n",
    "\n",
    "Example: Ice cream sales and drowning deaths correlate, but hot weather (a third factor) causes both.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a265383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Types of Optimizers (with Explanation & Examples):\\n1. Stochastic Gradient Descent (SGD)\\nHow it works: Updates model parameters using the gradient of the loss with respect to a random sample of data at each step.\\n\\nPros: Simple, works well with large datasets.\\n\\nCons: Slow convergence; may oscillate.\\n\\nExample (PyTorch):\\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\\n\\n\\n2. Momentum\\nHow it works: Adds a fraction of the previous update to the current one to accelerate convergence and avoid oscillations.\\n\\nPros: Faster convergence than plain SGD.\\n\\nExample:\\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\\n\\n\\n3. AdaGrad (Adaptive Gradient Algorithm)\\nHow it works: Adapts learning rate for each parameter by scaling it inversely proportional to the square root of all past gradients.\\n\\nPros: Good for sparse data.\\n\\nCons: Learning rate becomes very small over time.\\n\\nExample:\\n\\noptimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\\n\\n\\n4. RMSProp (Root Mean Square Propagation)\\nHow it works: Uses a moving average of squared gradients to normalize the gradient.\\n\\nPros: Solves AdaGrad's learning rate decay issue; good for RNNs.\\n\\nExample:\\noptimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\\n\\n\\n5. Adam (Adaptive Moment Estimation)\\nHow it works: Combines momentum and RMSProp. It uses moving averages of both the gradients and the squared gradients.\\n\\nPros: Fast convergence, widely used, robust.\\n\\nCons: Slightly more complex, but better performance in most cases.\\n\\nExample:\\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\\n\\n\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
    "'''\n",
    "An optimizer is an algorithm that adjusts the parameters (weights and biases) of a model to minimize the loss function during training.\n",
    "It plays a critical role in how fast and how well your model learns.\n",
    "\n",
    "'''\n",
    "'''Types of Optimizers (with Explanation & Examples):\n",
    "1. Stochastic Gradient Descent (SGD)\n",
    "How it works: Updates model parameters using the gradient of the loss with respect to a random sample of data at each step.\n",
    "\n",
    "Pros: Simple, works well with large datasets.\n",
    "\n",
    "Cons: Slow convergence; may oscillate.\n",
    "\n",
    "Example (PyTorch):\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "2. Momentum\n",
    "How it works: Adds a fraction of the previous update to the current one to accelerate convergence and avoid oscillations.\n",
    "\n",
    "Pros: Faster convergence than plain SGD.\n",
    "\n",
    "Example:\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "3. AdaGrad (Adaptive Gradient Algorithm)\n",
    "How it works: Adapts learning rate for each parameter by scaling it inversely proportional to the square root of all past gradients.\n",
    "\n",
    "Pros: Good for sparse data.\n",
    "\n",
    "Cons: Learning rate becomes very small over time.\n",
    "\n",
    "Example:\n",
    "\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "4. RMSProp (Root Mean Square Propagation)\n",
    "How it works: Uses a moving average of squared gradients to normalize the gradient.\n",
    "\n",
    "Pros: Solves AdaGrad's learning rate decay issue; good for RNNs.\n",
    "\n",
    "Example:\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "5. Adam (Adaptive Moment Estimation)\n",
    "How it works: Combines momentum and RMSProp. It uses moving averages of both the gradients and the squared gradients.\n",
    "\n",
    "Pros: Fast convergence, widely used, robust.\n",
    "\n",
    "Cons: Slightly more complex, but better performance in most cases.\n",
    "\n",
    "Example:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "764dac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A module in scikit-learn for linear models like:\\n\\nLinearRegression\\n\\nLogisticRegression\\n\\nRidge, Lasso, etc.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#17. What is sklearn.linear_model?\n",
    "'''A module in scikit-learn for linear models like:\n",
    "\n",
    "LinearRegression\n",
    "\n",
    "LogisticRegression\n",
    "\n",
    "Ridge, Lasso, etc.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f0dd9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The method model.fit() is used to train a machine learning model on a dataset.\\nIt adjusts the model's parameters (like weights in a neural network or coefficients in linear regression) by minimizing a loss function based on the training data.\\nThe arguments depend on the model and library we're using, but for scikit-learn models:\\n\\nX_train: Features (independent variables)\\n\\ny_train: Labels or target values (dependent variable)\\n\\n\\nmodel.fit(X_train, y_train) \""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#18. What does model.fit() do? What arguments must be given?\n",
    "'''The method model.fit() is used to train a machine learning model on a dataset.\n",
    "It adjusts the model's parameters (like weights in a neural network or coefficients in linear regression) by minimizing a loss function based on the training data.\n",
    "The arguments depend on the model and library we're using, but for scikit-learn models:\n",
    "\n",
    "X_train: Features (independent variables)\n",
    "\n",
    "y_train: Labels or target values (dependent variable)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train) '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e93dc79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.predict() generates predictions using a trained model.\\n Required Argument:\\n model.predict(X_test)\\nX_test: Feature data (same structure as training features)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#19. What does model.predict() do? What arguments must be given?\n",
    "'''model.predict() generates predictions using a trained model.\n",
    " Required Argument:\n",
    " model.predict(X_test)\n",
    "X_test: Feature data (same structure as training features)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0077f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Type\\tDescription\\tExamples\\nContinuous\\tNumeric values with infinite possible values\\tHeight, age, income\\nCategorical\\tDiscrete values representing categories\\tGender, color, product type'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20. What are continuous and categorical variables?\n",
    "'''Type\tDescription\tExamples\n",
    "Continuous\tNumeric values with infinite possible values\tHeight, age, income\n",
    "Categorical\tDiscrete values representing categories\tGender, color, product type'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e113b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Feature scaling transforms features so they’re on a similar scale.\\n\\n Why it helps:\\nAlgorithms like KNN, SVM, Logistic Regression, and Gradient Descent perform better when input features are scaled.\\n\\nPrevents features with large ranges from dominating the model.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#21.  What is feature scaling? How does it help in Machine Learning?\n",
    "'''Feature scaling transforms features so they’re on a similar scale.\n",
    "\n",
    " it helps in ML:\n",
    "Algorithms like KNN, SVM, Logistic Regression, and Gradient Descent perform better when input features are scaled.\n",
    "\n",
    "Prevents features with large ranges from dominating the model.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c07f5927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Using sklearn.preprocessing module:\\n\\nExample: Standard Scaling (mean = 0, std = 1)\\nfrom sklearn.preprocessing import StandardScaler\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\nExample: Min-Max Scaling (range [0, 1])\\nfrom sklearn.preprocessing import MinMaxScaler\\nscaler = MinMaxScaler()\\nX_scaled = scaler.fit_transform(X)\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#22. How do we perform scaling in Python?\n",
    "'''Using sklearn.preprocessing module:\n",
    "\n",
    "Example: Standard Scaling (mean = 0, std = 1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "Example: Min-Max Scaling (range [0, 1])\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97989f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It’s a module in scikit-learn that provides tools for:\\n\\nFeature scaling (StandardScaler, MinMaxScaler)\\n\\nEncoding categorical data (OneHotEncoder, LabelEncoder)\\n\\nImputation (filling missing values)\\n\\nBinarization, Normalization, and more\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#23. What is sklearn.preprocessing?\n",
    "'''It’s a module in scikit-learn that provides tools for:\n",
    "\n",
    "Feature scaling (StandardScaler, MinMaxScaler)\n",
    "\n",
    "Encoding categorical data (OneHotEncoder, LabelEncoder)\n",
    "\n",
    "Imputation (filling missing values)\n",
    "\n",
    "Binarization, Normalization, and more\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ca781cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Using train_test_split:\\nfrom sklearn.model_selection import train_test_split\\n\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=42)\\n\\n    test_size=0.2 → 20% test, 80% train\\n\\nrandom_state ensures reproducibility\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#24.  How do we split data for training and testing in Python?\n",
    "'''Using train_test_split:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    test_size=0.2 → 20% test, 80% train\n",
    "\n",
    "random_state ensures reproducibility\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fea0cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nData encoding converts categorical data into numeric format so ML models can use it.\\n\\nCommon encoding techniques:\\n| Method          | Description                              | Use Case                         ||\\n| Label Encoding  | Converts categories to numbers           | Ordered categories               |\\n| One-Hot Encoding| Creates binary columns for each category | Unordered, nominal categories    |\\n| Ordinal Encoding| Assigns integer values to ordered labels | Ratings like low < medium < high |\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#25.Explain data encoding\n",
    "\n",
    "\"\"\"\n",
    "Data encoding converts categorical data into numeric format so ML models can use it.\n",
    "\n",
    "Common encoding techniques:\n",
    "| Method          | Description                              | Use Case                         ||\n",
    "| Label Encoding  | Converts categories to numbers           | Ordered categories               |\n",
    "| One-Hot Encoding| Creates binary columns for each category | Unordered, nominal categories    |\n",
    "| Ordinal Encoding| Assigns integer values to ordered labels | Ratings like low < medium < high |\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bbf22c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
